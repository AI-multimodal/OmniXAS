{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL OMNIXAS PACKAGE\n",
    "# run this once in the beginning to install the package\n",
    "#  no need to run second time\n",
    "! pip install -v \"git+https://github.com/AI-multimodal/OmniXAS.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from omnixas.data import MLSplits\n",
    "from omnixas.model.metrics import ModelMetrics\n",
    "from omnixas.model.xasblock_regressor import XASBlockRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"dataset/omnixas_2\"\n",
    "\n",
    "def fetch_dataset_elements(data_dir):\n",
    "    \"parses filenames in directory to get the element for which data is available\"\n",
    "    files = os.listdir(data_dir)\n",
    "    elements = [file.split(\"_\")[-1].split(\".\")[0] for file in files if \"json\" in file]\n",
    "    return elements\n",
    "\n",
    "elements = fetch_dataset_elements(DATA_DIR+\"/spectra\")\n",
    "print(f\"Found data for {len(elements)} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = elements[0] # select different  elements here\n",
    "element = \"Cu\"\n",
    "split_json = json.load(open(f\"{DATA_DIR}/splits/split_{element}.json\"))\n",
    "split = MLSplits.parse_obj(split_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XASBLOCK model \n",
    "model = XASBlockRegressor(\n",
    "    directory=f\"checkpoints/{element}\",\n",
    "    max_epochs=100,\n",
    "    early_stopping_patience=25,  # stops if val_loss does not improve for 25 epochs\n",
    "    overwrite_save_dir=True,  # delete save_dir else adds new files to it\n",
    "    input_dim=64,\n",
    "    output_dim=200,\n",
    "    hidden_dims=[200,200],\n",
    "    initial_lr=1e-2,  # initial learning rate, will be optimized by lr finder later\n",
    "    batch_size=128,\n",
    ")\n",
    "model.fit(split) # full split object needs to be passed coz it contains val data used in logging\n",
    "# model.load()  # to load saved model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE this to monitor training progress\n",
    "# refer to this to understand implication  of train/val loss:\n",
    "# https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/ \n",
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard # to restart tensorboard\n",
    "\n",
    "%tensorboard --logdir checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE MODELS\n",
    "# using any simple model you want https://scikit-learn.org/1.5/supervised_learning.html\n",
    "# model = MultiOutputRegressor(SVR())  \n",
    "# model.fit(split.train.X, split.train.y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = split.val.y\n",
    "predictions = model.predict(split.val.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting predictions in validation set\n",
    "plt.plot(predictions.T, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eta(split, metrics):\n",
    "    train_mean = split.train.y.mean(axis=0)\n",
    "    targets = split.val.y\n",
    "    mean_model_predictions = np.tile(train_mean, (targets.shape[0], 1))\n",
    "    mean_model_metrics = ModelMetrics(\n",
    "        targets=targets,\n",
    "        predictions=mean_model_predictions,\n",
    "    )\n",
    "    return (\n",
    "        mean_model_metrics.median_of_mse_per_spectra / metrics.median_of_mse_per_spectra\n",
    "    )\n",
    "metrics = ModelMetrics(predictions=predictions, targets=targets)\n",
    "eta = get_eta(split, metrics)\n",
    "print(f\"MSE: {metrics.mse}\", f\"eta: {eta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(metrics.mse_per_spectra), bins=20, alpha=0.5, density=True)\n",
    "plt.xlabel(\"log(MSE)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(f\"Element: {element} \\n eta: {round(eta, 2)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = metrics.deciles\n",
    "fig, axs = plt.subplots(9, 1, figsize=(6, 20))\n",
    "for i, (d, ax) in enumerate(zip(deciles, axs)):\n",
    "    ax.plot(d[0], label=\"target\")\n",
    "    ax.plot(d[1], label=\"prediction\")\n",
    "    ax.fill_between(\n",
    "        range(len(d[0])),\n",
    "        d[0],\n",
    "        d[1],\n",
    "        alpha=0.5,\n",
    "        interpolate=True,\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Decile {i+1}\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
