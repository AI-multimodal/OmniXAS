trainer:
  _target_: lightning.Trainer
  max_epochs: 1000
  log_every_n_steps: 1
  check_val_every_n_epoch: 2
  devices: 1
  callbacks:
    - ${callbacks.lr_finder}
    - ${callbacks.lr_monitor}
    - ${callbacks.model_checkpoint}
    - ${callbacks.train_val_loss}
    - ${callbacks.early_stopping}

callbacks:
  lr_finder:
    _target_: lightning.pytorch.callbacks.lr_finder.LearningRateFinder
  lr_monitor:
    _target_: lightning.pytorch.callbacks.lr_monitor.LearningRateMonitor
    logging_interval: "epoch"
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${hydra:run.dir}/checkpoints
    filename: "best-model-{epoch:02d}-{val_loss:.4f}"
    monitor: val_loss
    mode: min
    save_top_k: 1
    verbose: False
    auto_insert_metric_name: True
    save_last: True
  train_val_loss:
    _target_: refactor.utils.lightning_callbacks.TensorboardLogTestTrainLoss
  early_stopping:
    _target_: lightning.pytorch.callbacks.early_stopping.EarlyStopping
    monitor: val_loss
    patience: 25 # 50 (25 if logging every 2 epochs, else 50)
    mode: min
    verbose: True
